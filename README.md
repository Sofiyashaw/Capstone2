                                              Sign Language Detection - ASL Dataset
<p align="center">
    <img src="https://github.com/Sofiyashaw/Capstone2/blob/main/sign-language.jpg" alt="Logo" width="500" height="350"/>
</p> 
<p align="center">

- Project Overview <br>
This project focuses on detecting American Sign Language (ASL) gestures using machine learning. By training a model on the ASL dataset, the system can identify and classify different ASL signs from input images.

- Dataset  <br>
The ASL dataset includes images of various ASL hand signs, covering the alphabet (A-Z) and numbers. Each sample is labeled with the corresponding gesture, enabling supervised learning.

- Project Workflow  <br>

- Data Preparation <br>
Preprocessed images, normalized pixel values, and split data into training and validation sets.
- Model Training  <br>
Trained a convolutional neural network (CNN) to classify hand signs accurately.
- Evaluation  <br>
Assessed model performance with accuracy and validation loss to ensure robustness.
- Model Performance  <br>
The trained model achieved a good accuracy on the validation set, showing reliable recognition of ASL signs.

- Future Enhancements  <br>

Experiment with additional gestures or complex hand movements.  <br>
Improve accuracy with deeper models or hyperparameter tuning.  <br>
Deploy the model in a real-time application with camera input.  <br>
